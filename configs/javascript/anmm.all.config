{
  "dataset": "stackOF/python_linear/",
  "out_file": "training_scores/python/anmm.linear",
  "net_name": "ANMM_linear",
  "global":{
      "model_type": "PY",
      "weights_file": "trained_weights/python/anmm.linear.weights",
      "save_weights_iters": 10,
      "num_iters": 700,
      "display_interval": 10,
      "test_weights_iters": 700,
      "optimizer": "adadelta",
      "learning_rate": 0.00001
  },
  "inputs": {
    "share": {
        "text1_corpus": "stackOF/python_linear/corpus_preprocessed.txt",
        "text2_corpus": "stackOF/python_linear/corpus_preprocessed.txt",
        "text3_corpus": "stackOF/python_linear/corpus_preprocessed.txt",
        "text4_corpus": "stackOF/python_linear/corpus_preprocessed.txt",
        "use_dpool": false,
        "embed_size": 200,
        "embed_path": "stackOF/python_linear/embed_glove_d200",
        "vocab_size": ?,
        "train_embed": false,
        "target_mode": "ranking",
        "bin_num": 20,
        "text1_maxlen": 10
    },
    "train": {
        "input_type": "DRMM_PairGenerator_linear",
        "phase": "TRAIN",
        "use_iter": false,
        "query_per_iter": 50,
        "batch_per_iter": 5,
        "batch_size": 100,
        "relation_file_title": "stackOF/python_linear/relation_train_title.txt",
        "relation_file_question": "stackOF/python_linear/relation_train_question.txt",
        "relation_file_answer": "stackOF/python_linear/relation_train_answer.txt",
        "hist_feats_file_title": "stackOF/python_linear/relation_train_title.binsum-20.txt",
        "hist_feats_file_question": "stackOF/python_linear/relation_train_question.binsum-20.txt",
        "hist_feats_file_answer": "stackOF/python_linear/relation_train_answer.binsum-20.txt"
    },
    "valid": {
        "input_type": "DRMM_ListGenerator_linear",
        "phase": "EVAL",
        "batch_list": 10,
        "relation_file_title": "stackOF/python_linear/relation_valid_title.txt",
        "relation_file_question": "stackOF/python_linear/relation_valid_question.txt",
        "relation_file_answer": "stackOF/python_linear/relation_valid_answer.txt",
        "hist_feats_file_title": "stackOF/python_linear/relation_valid_title.binsum-20.txt",
        "hist_feats_file_question": "stackOF/python_linear/relation_valid_question.binsum-20.txt",
        "hist_feats_file_answer": "stackOF/python_linear/relation_valid_answer.binsum-20.txt"
    },
    "test": {
        "input_type": "DRMM_ListGenerator_linear",
        "phase": "EVAL",
        "batch_list": 10,
        "relation_file_title": "stackOF/python_linear/relation_test_title.txt",
        "relation_file_question": "stackOF/python_linear/relation_test_question.txt",
        "relation_file_answer": "stackOF/python_linear/relation_test_answer.txt",
        "hist_feats_file_title": "stackOF/python_linear/relation_test_title.binsum-20.txt",
        "hist_feats_file_question": "stackOF/python_linear/relation_test_question.binsum-20.txt",
        "hist_feats_file_answer": "stackOF/python_linear/relation_test_answer.binsum-20.txt"
    },
    "predict": {
        "input_type": "DRMM_ListGenerator_linear",
        "phase": "PREDICT",
        "batch_list": 10,
        "relation_file": "stackOF/python_linear/relation_test.txt",
        "hist_feats_file": "stackOF/python_linear/relation_test.binsum-20.txt"
    }
  },
  "outputs": {
    "predict": {
      "save_format": "TREC",
      "save_path": "result/python/anmm.tit.txt"
    }
  },
  "model": {
    "model_path": "./matchzoo/models/",
    "model_py": "anmm.ANMM",
    "setting": {
        "num_layers": 2,
        "hidden_sizes": [20, 1],
	    "dropout_rate": 0.0
    }
  },
  "losses": [
    {
       "object_name": "rank_hinge_loss" ,
       "object_params": {
            "margin": 1.0
       }
    }
  ],
  "metrics": [ "ndcg@10", "ndcg@100", "mrr" ]
}

